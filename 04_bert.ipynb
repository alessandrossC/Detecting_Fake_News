{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessandrossC/Detecting_Fake_News/blob/main/04_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTOyPFtOMQlA"
      },
      "outputs": [],
      "source": [
        "! pip install -U datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KRTHbS8Mp8l",
        "outputId": "673d9dbc-15f6-463f-b0f8-00ef87f09065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import Dataset, load_dataset\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import logging\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(7)\n",
        "np.random.seed(7)\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZlYxjxM5Mq"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content/processed'\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv.zip'), compression='zip')\n",
        "val_df = pd.read_csv(os.path.join(DATA_PATH, 'val.csv.zip'), compression='zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZO-0_7POp9Z"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[['title', 'text', 'is_fake']]\n",
        "val_df = val_df[['title', 'text', 'is_fake']]\n",
        "\n",
        "text_columns = ['title', 'text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LGTQaCiOyDp"
      },
      "outputs": [],
      "source": [
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "# Use copy=True to avoid the NumPy warning\n",
        "train_dataset = Dataset.from_pandas(train_df.copy())\n",
        "val_dataset = Dataset.from_pandas(val_df.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "e7c678696a674aaf901cdafca1990ce3",
            "8f4bf29cf4ee4971a63c5ae634d618f0",
            "b66b48f1c4f44944b432cf0a494b7f4c",
            "a0b2033e783948ae8c3dcae5fa5bce29",
            "0a65d37821f84f2380e219f82e5ac96d",
            "f4afef3207754f2a879342b816b2695a",
            "c344cd80cb9048d5bcf7784480a567bf",
            "006dbc70f5e94625a509413a7fa661e0",
            "e41ad3a733864ecfb477d1590283215d",
            "3aad7b176246442ba4aa07314af1f7e4",
            "7d5e9b5f5da0487092f6319ec773cf07",
            "3bc72b932a694ff0ad07bdb9cb184b70",
            "4d765fd69d914c22a46445273265ea71",
            "69cd883e0e134feb96b39bdb6fa49f15",
            "e92eede4b5a34c4cbf133cd9a3a3115b",
            "d694307106554107bcd390f0d0f4e2e5",
            "fa61a20c3fd14a2cb0b1fc8b40a29df3",
            "8d13820e8862449a86d11681a01bec79",
            "2fce2f4398f94df48b84f454cad4b345",
            "1b12e6dc8b1041c9a3bf5967d1e190dd",
            "c52d63a9627841aba47ed831a4f7a45f",
            "46ea294bf3c74fb1922300a1cf05a724",
            "8495f0b527aa482c8a7a70f57f3b847b",
            "0eafe6b4349f47fd9c0aaee9a4f81d3c",
            "794e7de661df46ec9eba46b7c86e8692",
            "4daa385529e24c82a41e550b89781393",
            "edb7927f73034533978b7bac9b6d42e4",
            "1af909248cd64503abac4e642dfed46e",
            "79a0a75a1950474e8e5dca7e8ef5379c",
            "145bbde08950441d917b18580bc28ae6",
            "7823a3e42b3440a99a4a05096b05bb26",
            "20380b062969432f9767b300f7840cbc",
            "d05f67cc5ce8469b8e624835b94182a1",
            "3f11fbbaa34f4b789eca45f42a7a88f1",
            "206aa0cb9991428bad3cb8782d047190",
            "62ae57b948214eab91b8af1796d87ef0",
            "97a65b5a8539495c88e42efb958cd50c",
            "fca29e13002f4660bef3e96cc7d3995a",
            "ec9e9dbbf16a4f09bb10f9081ef70f4f",
            "c79678f61136465cb575e97cd61fc94a",
            "c6d8693f7f514b5f937431f07fdc19fa",
            "dbc92d67df494cc2be3e3a411f41d107",
            "33ae2aeb99de445b97604b3b0fe107ce",
            "69d2c93595fd4b1db9cb7dab4a267c7a"
          ]
        },
        "id": "rzViZ271PDjb",
        "outputId": "556f3393-b5bd-4a5f-f720-b38e260f39c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7c678696a674aaf901cdafca1990ce3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bc72b932a694ff0ad07bdb9cb184b70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8495f0b527aa482c8a7a70f57f3b847b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f11fbbaa34f4b789eca45f42a7a88f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0iP_2jBPkYw"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "\n",
        "    return tokenizer(\n",
        "        example[\"title\"],\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "def prepare_dataset(dataset, tokenize_function):\n",
        "    # dataset — це HuggingFace Dataset, а не DataFrame!\n",
        "    tokenized_dataset = dataset.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        remove_columns=['title', 'text']\n",
        "    )\n",
        "    tokenized_dataset = tokenized_dataset.rename_column(\"is_fake\", \"labels\")\n",
        "    return tokenized_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "805988b0a15e475f8730f35c5e952527",
            "05e9dd86d60e47ce853d2f37684c9cb9",
            "a7d37f8737944b229c10ede7314c1f31",
            "fb1ac61a3206459fbd8f7457c8f7061f",
            "a275da276ed44264881329aa12495e22",
            "9609139effbd4339845dd6b36493f6a9",
            "ff501261a6fd4b7a936106c443e21a61",
            "db991d39c95a4e95a02a9c214f5f111e",
            "088898672f214405a17ed012f817143c",
            "b578b49ca3644c2db191646345636afb",
            "32ae32c4b1aa45a28f0b95ef8a450277",
            "2104295448a54f4a88b0bc0f3102a500",
            "0cde617cc7e2423588863b9ced4b2c58",
            "f6675151addd4496acf1c721c788b352",
            "29678a383b3c4e3a95451543f4c9a8b6",
            "7fbd959f7b8842c4aab4198bf44dbf4b",
            "3d6f71d750c94f9b83d2b531758379eb",
            "46c5596659cf4eb1bd78221af9128a73",
            "41f4009c26aa4200bf68a09d1001b9fe",
            "7f8ebd42a22441dd935846a6b90ad6d8",
            "a3a64a9ebdd6474fa009c5e8e054d32f",
            "3d71f3f0a63346fcb7f1d875542d67db"
          ]
        },
        "id": "VcPFnzEKP6k2",
        "outputId": "f648ced9-fec7-472d-c0e6-3ba852be2bdc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "805988b0a15e475f8730f35c5e952527",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28595 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2104295448a54f4a88b0bc0f3102a500",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7149 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create datasets using tokenize_function\n",
        "tokenized_train_dataset = prepare_dataset(train_dataset, tokenize_function)\n",
        "tokenized_val_dataset = prepare_dataset(val_dataset, tokenize_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "2ce67f4b3f8d4103a6116277f28249f3",
            "c7544c4c1e584b37a557cbd1961c8f15",
            "848ea2f185404364ab0268d57dd9a49d",
            "7d1c1ab6a6554c58ac83ae00faa69dd7",
            "cc23ef28d9c14bf7893bf7e322a75447",
            "9b6a426f452f422e8499440fa323da33",
            "b4766acfb9804a76bf9c613a4340df93",
            "b8054740cc8c4b1c8be7ecf7c46e10d4",
            "962e425673374adbaee10fbd5ff595a8",
            "18174daefdd6446a85d836e955d8ff50",
            "6bddbf34fced40ffbb79a6b210d23fd1",
            "a065dee61ace4c43a61005231da45f6e",
            "e4cf6dd623434822bc44018f25b80782",
            "031c80f14e204ef886d3d67ff50d7863",
            "b500db92f97c4a60a620c3a4bb0c0bca",
            "daa797dacd094092b9bf32e32409dcc0",
            "a8ea2dc6ef524126ba5e815943d36a1c",
            "04283a28a6da43dbb07e73588fae92c7",
            "922d27ea1e254a1882478f99faa7439e",
            "12db3d5f037040fcbf251687acbe5ca8",
            "bb51561156604c8d8143a113d8fea32a",
            "471c179c5e9f494ea451ec85f2f6cadd"
          ]
        },
        "id": "PyiBpA05Q5bk",
        "outputId": "fdf2f235-918e-4f06-f9d9-d4db55cf42a2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ce67f4b3f8d4103a6116277f28249f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/29 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a065dee61ace4c43a61005231da45f6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "11123844"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_train_dataset.to_parquet(DATA_PATH + '/tokenized_train_dataset.parquet')\n",
        "tokenized_val_dataset.to_parquet(DATA_PATH + '/tokenized_val_dataset.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "5ccb0af06a444e00bc053085880bfe41",
            "fc797b71d373419589e917e4511eb21f",
            "5c145e25dd9c436eb02a04350e088110",
            "3cb72677c92c4375ac10e29f328fd395",
            "d9192d660ba64a02aa9cd0838a9dcf96",
            "5886c8a9969f41cf8d1cbc9055f148c1",
            "903133808ec742baa688e1b806b339d1",
            "bcc1271d75c841a5ac448dbe05b5f78e",
            "23752693c0ec4ff3a42c76760dad6644",
            "a7f894c952814ce08251d4f1ed20bed4",
            "81b760f9b72b483b8b946498d22bb626",
            "013804b75b9649dcb263ec9a4b2c9123",
            "9077e493316d4feda86ec6c468ba3aa5",
            "93d62ae6672e41d3a595c9062594d9b8",
            "b3b98de88e99484b98e9094f237c3d26",
            "25af097d0bdf4ec89bd20e84fe49ae77",
            "2317f86a20de418cb3fc73f382169a01",
            "12d4c50a8b1d4b3a90fc4274a53b9102",
            "82ca4629553f44b5ad69c98bcc9b6c3d",
            "6608d05c3f204704bed40da179383320",
            "6167d921e5c345b1927ec421e3e73ff6",
            "6f9ec72d29894811bb87e25d4981616c"
          ]
        },
        "id": "M3FtRHCNRCA-",
        "outputId": "7b5563cf-2495-43ef-e9c5-da37fc10cd9f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ccb0af06a444e00bc053085880bfe41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "013804b75b9649dcb263ec9a4b2c9123",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_files = {\n",
        "  'train': 'tokenized_train_dataset.parquet',\n",
        "  'validation': 'tokenized_val_dataset.parquet',\n",
        "\n",
        "}\n",
        "\n",
        "raw_datasets = load_dataset('parquet', data_dir=DATA_PATH, data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0VrE7e9RHuf"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = raw_datasets['train']\n",
        "tokenized_val_dataset = raw_datasets['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "484G5J-aRLRO"
      },
      "outputs": [],
      "source": [
        "# Create data loaders with DataCollatorWithPadding\n",
        "train_loader = DataLoader(\n",
        "    tokenized_train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    tokenized_val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52Fkj9N_RYuo"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "batch_size = 16\n",
        "learning_rate = 1e-5\n",
        "epochs = 2\n",
        "warmup_steps = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853,
          "referenced_widgets": [
            "8f25eac465ab4afeb5c006a6d1e01406",
            "036e25bd513348a78d692d6f5c35c43a",
            "4ba57acb981c4071b168332520dbb6f5",
            "b60b7cfca21d4eb89b8e0b747a2a4ba2",
            "42a3401301cd458a9a8aa6f541d237e8",
            "5d2797e4bf6d42db9642cfaf34867f98",
            "0843dc2a5cd74770b771b9a39de4e3f5",
            "27905362947043548422b2d0b158f666",
            "abb4ad98edb84fe59e4b7bb8e2375062",
            "28f92f47c5144544bac99aa03ab0c9e2",
            "628d2fea9ab140c4b66c6ca8d46cc10b"
          ]
        },
        "id": "Jb9n2liiRjyd",
        "outputId": "75f0491d-47f4-499c-8084-840e4ee04aa9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f25eac465ab4afeb5c006a6d1e01406",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmNdz77vR5y0"
      },
      "outputs": [],
      "source": [
        "# Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eislFDo3SKfj"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Ground truth labels.\n",
        "        y_pred (torch.Tensor): Raw logits or predicted labels.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy as a percentage (0-100).\n",
        "    \"\"\"\n",
        "    # Якщо y_pred — logits, потрібно взяти argmax:\n",
        "    if y_pred.ndim > 1 and y_pred.size(1) > 1:\n",
        "        y_pred_labels = torch.argmax(y_pred, dim=1)\n",
        "    else:\n",
        "        y_pred_labels = y_pred\n",
        "\n",
        "    correct = torch.eq(y_true, y_pred_labels).sum().item()\n",
        "    acc = (correct / len(y_pred_labels)) * 100\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KJkrASbSoFv"
      },
      "outputs": [],
      "source": [
        "def train_step(model, data_loader, optimizer, scheduler, loss_fn, accuracy_fn, device):\n",
        "    \"\"\"Training step for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch in tqdm(data_loader, desc='Training'):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss = loss_fn(logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        train_acc += accuracy_fn(labels, logits.argmax(dim=1))\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZwyvJm_i2nn"
      },
      "outputs": [],
      "source": [
        "def test_step(model, data_loader, loss_fn, accuracy_fn, device):\n",
        "    model.eval()\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss = loss_fn(logits, labels)\n",
        "            test_loss += loss.item()\n",
        "            test_acc += accuracy_fn(labels, logits.argmax(dim=1))\n",
        "\n",
        "            # Get probabilities for log-loss calculation\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            probabilities.extend(probs.cpu().numpy())\n",
        "\n",
        "            # Get predictions for F1 score\n",
        "            preds = logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions)\n",
        "\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}% | Test F1 Score: {f1:.4f}\")\n",
        "    return {\n",
        "        'loss': test_loss,\n",
        "        'accuracy': test_acc,\n",
        "        'f1_score': f1,\n",
        "        'predictions': predictions,\n",
        "        'true_labels': true_labels,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "6d71b247023042c3a8eca9bfe48f3768",
            "59df6fbaaea14daaad390d91d7e49a0f",
            "4f116546190540e5ab20c822eec35d9a",
            "841ed8cfb72a4b998622f45d9674e59a",
            "fe82ca3ee9dd4aa1a8c3a244ac395001",
            "be8e80c9f3894ca6960b5a3b091b2103",
            "15b48e8ef4574502ab08464e47bd7f95",
            "4e448203deeb446bab652a157dbdbb4a",
            "95fc93692d114a22b0c585739f527965",
            "6860a00504bb41eca73b705fd1e55162",
            "e3e48b2311434d859ade6b750d867c9b",
            "aca7a5c7bf114a29a3328b82aa00ee95",
            "14687b03240a4acda861f4a1b3b8d1b4",
            "16b7b13eb5be4a22995ab471d04e7e46",
            "9955c4c806b4414d8628d15f40685ed5",
            "266f5cd90c7648bbb84f567309f23548",
            "38cda680c7e84934a12575b65ec8e9da",
            "43ed8e0840524436849dcb012adccc7a",
            "b497ba9ad41c4de5a41af4b4d627f89b",
            "b708753f99b2488eb1333b034ad7f4ed",
            "47f0803221c84111a97a026cb730eab1",
            "0831a3c9d8594c40be9aa589efa38b79",
            "e451d2127240486da1657dabe740cda9",
            "eb05c83468634e3a8081f273103a61ee",
            "d542e8bcd4de4d09a34c3c97c84d9015",
            "418b0cb56c3a41378f81428463dc00a2",
            "bf7422745db1421d8d627afd676f3d54",
            "3e6c6d64bddf47abb94bf2684ab10753",
            "0df3de68f1ea42f0a5da9876ab3bacb2",
            "e2fa7e33b268409b900ea47200b0110e",
            "33c711be0ff44902b2f0d05f26b77d0b",
            "e51e3e475a9f4529af972900b39136e9",
            "bf6631beb99e4a93938fca0b4fe0f2f4",
            "969ac8e66e1145ff90e7d1e6a133f26f",
            "ef0b1775f399458a84c02550718178f8",
            "a238bb6104794e58bf45cf18ea5a7588",
            "231df41b23994bf1b0133cdcc9f0637b",
            "4d500b79b1ca48638735a06b892b9347",
            "2e1292963d164159beb938fc343e1dc5",
            "fc84d4d39aff444780e36e91c93b2573",
            "0189d0003ae848df9c8b0fe756482603",
            "b4cded9fca68410c9f7d721f3320ed18",
            "4e9bd655ae5e4861801109b75ece77c6",
            "1ac8c060a239451081799cbb9e8f41c1"
          ]
        },
        "id": "Le74stPcUDMM",
        "outputId": "d226ee6a-bcb2-47a3-93e1-b8ca04cd465c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 1/2\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d71b247023042c3a8eca9bfe48f3768",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/1788 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.08483 | Train accuracy: 96.35%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aca7a5c7bf114a29a3328b82aa00ee95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/447 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.00590 | Test accuracy: 99.92% | Test F1 Score: 0.9992\n",
            "\n",
            "Epoch 2/2\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e451d2127240486da1657dabe740cda9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/1788 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.00205 | Train accuracy: 99.95%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "969ac8e66e1145ff90e7d1e6a133f26f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/447 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.00048 | Test accuracy: 99.99% | Test F1 Score: 0.9999\n",
            "\n",
            "Training completed!\n",
            "\n",
            "Final Results:\n",
            "Best Validation Log Loss: 0.0005\n",
            "Best Validation F1 Score: 0.9999\n",
            "Best Validation Accuracy: 99.99%\n"
          ]
        }
      ],
      "source": [
        "# Training Loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_f1_scores = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Training\n",
        "    train_loss = train_step(model, train_loader, optimizer, scheduler, loss_fn, accuracy_fn, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation (залишаєш)\n",
        "    val_results = test_step(model, val_loader, loss_fn, accuracy_fn, device)\n",
        "    val_losses.append(val_results['loss'])\n",
        "    val_accuracies.append(val_results['accuracy'])\n",
        "    val_f1_scores.append(val_results['f1_score'])\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"Best Validation Log Loss: {min(val_losses):.4f}\")\n",
        "print(f\"Best Validation F1 Score: {max(val_f1_scores):.4f}\")\n",
        "print(f\"Best Validation Accuracy: {max(val_accuracies):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvYYLajxBZF8"
      },
      "source": [
        "he model demonstrates outstanding performance on the validation set, achieving nearly perfect F1 score and accuracy. Such results may indicate very strong learning, but it is also worth checking for potential data leakage, label errors, or a too-easy classification task. If the validation set is representative and correctly separated, this means the model has learned to distinguish fake news with almost complete confidence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Iy0F-qSA1nB",
        "outputId": "19370e3a-1082-4235-9fd2-692ac703411b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model saved to './fack_news_model'\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = '/content/models/fack_news_model'\n",
        "model.save_pretrained(MODEL_PATH)\n",
        "tokenizer.save_pretrained(MODEL_PATH)\n",
        "print(\"\\nModel saved to './fack_news_model'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0-Tq8VTBduT",
        "outputId": "72fbfd7e-7aa4-4e82-98f5-bda26cd9f953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example Prediction:\n",
            "Title: Big changes coming to city parking regulations\n",
            "Text: The city council has announced a series of major reforms to parking...\n",
            "Is Fake: True\n",
            "Probability (fake): 0.9991\n",
            "Confidence: 0.9991\n"
          ]
        }
      ],
      "source": [
        "def predict_is_fake(title, text, model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Predict if a news article is fake (1) or real (0)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        title,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    probability_fake = predictions[0][1].item()  # Probability of class 1 (\"is_fake\"=1)\n",
        "    is_fake = probability_fake > 0.5\n",
        "\n",
        "    return {\n",
        "        'is_fake': is_fake,\n",
        "        'probability': probability_fake,\n",
        "        'confidence': max(probability_fake, 1 - probability_fake)\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "example_title = \"Big changes coming to city parking regulations\"\n",
        "example_text = \"The city council has announced a series of major reforms to parking...\"\n",
        "result = predict_is_fake(example_title, example_text, model, tokenizer, device)\n",
        "\n",
        "print(\"\\nExample Prediction:\")\n",
        "print(f\"Title: {example_title}\")\n",
        "print(f\"Text: {example_text}\")\n",
        "print(f\"Is Fake: {result['is_fake']}\")\n",
        "print(f\"Probability (fake): {result['probability']:.4f}\")\n",
        "print(f\"Confidence: {result['confidence']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PzVBU57DIOl"
      },
      "outputs": [],
      "source": [
        "experiment_results = {\n",
        "    'model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
        "    'log_loss_train': [0.0273, 0.0303, 0.1997],\n",
        "    'log_loss_val': [0.0310, 0.0867, 0.2001],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgpd8oakCask",
        "outputId": "2bb84d40-d250-4e25-a97c-626f57bd5434"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/processed/experiment_results.joblib']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH = '/content/processed'\n",
        "joblib.dump(experiment_results, os.path.join(DATA_PATH, 'experiment_results.joblib'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOPW-CksDq7Z"
      },
      "outputs": [],
      "source": [
        "experiment_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyciaP2EDYZf"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "results['model'] = 'BERT Fine-Tuning'\n",
        "results['log_loss_train'] = np.round(train_losses[-1], 5)\n",
        "results['log_loss_val'] = np.round(val_losses[-1], 5)\n",
        "experiment_results.append(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHtNwPRLD49k",
        "outputId": "5ea55cf2-378f-4d45-dcf7-e48ae35d1363"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/processed/experiment_results.joblib']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH = '/content/processed'\n",
        "\n",
        "joblib.dump(experiment_results, os.path.join(DATA_PATH, 'experiment_results.joblib'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4jFzqdwEGcA",
        "outputId": "00d63a2a-175c-4852-a45b-a5b8876992a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load fine-tuned model and tokenizer\n",
        "model_path = '/content/models/fack_news_model'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT9S_23bEzz3"
      },
      "outputs": [],
      "source": [
        "def custom_forward(model, embeddings, attention_mask):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
        "        probabilities = F.softmax(outputs.logits, dim=1)[:, 1]  # Ймовірність класу 1\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYQ8g99pGR47"
      },
      "outputs": [],
      "source": [
        "ig = IntegratedGradients(custom_forward)\n",
        "\n",
        "# Loop over random news articles\n",
        "for i in np.random.choice(df_val.index, size=3, replace=False):\n",
        "    title = df_val.loc[i, 'title']\n",
        "    text = df_val.loc[i, 'text']\n",
        "    true_label = df_val.loc[i, 'is_fake']\n",
        "\n",
        "    print(f\"\\n🔹 Example {i}:\")\n",
        "    print(f\"Title: {title}\")\n",
        "    print(f\"Text: {text[:120]}...\")  # Якщо текст довгий\n",
        "    print(f\"Is Fake: {bool(true_label)}\")\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        title,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        pred_label = \"Fake\" if probs[0][1] > 0.5 else \"Real\"\n",
        "\n",
        "    # Compute embeddings\n",
        "    input_embeddings = model.bert.embeddings(input_ids)\n",
        "\n",
        "    # Get attributions\n",
        "    attributions, delta = ig.attribute(\n",
        "        inputs=input_embeddings,\n",
        "        additional_forward_args=(attention_mask,),\n",
        "        return_convergence_delta=True,\n",
        "    )\n",
        "\n",
        "    # Prepare tokens and attribution scores\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    attr_scores = attributions[0].sum(dim=-1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    # Prepare visualization record\n",
        "    viz_data_record = visualization.VisualizationDataRecord(\n",
        "        word_attributions=attr_scores,\n",
        "        pred_prob=probs[0][1].item(),\n",
        "        pred_class=pred_label,\n",
        "        true_class=\"Fake\" if true_label else \"Real\",\n",
        "        attr_class=\"Fake\",\n",
        "        attr_score=sum(attr_scores),\n",
        "        raw_input_ids=tokens,\n",
        "        convergence_score=delta.item()\n",
        "    )\n",
        "\n",
        "    # Visualize\n",
        "    visualization.visualize_text([viz_data_record])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}